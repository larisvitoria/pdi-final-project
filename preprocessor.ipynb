{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35540ae2",
   "metadata": {},
   "source": [
    "# **Guia de Desenvolvimento: Pré-Processamento Modular para Segmentação e Classificação (CBIS-DDSM)**\n",
    "\n",
    "Este roteiro define as etapas de transformação para converter as imagens JPEG do Kaggle em tensores de alta fidelidade. O foco é a remoção de ruído sistemático e a preservação de sinais morfológicos críticos para a distinção entre patologias malignas e benignas.\n",
    "\n",
    "## 1. Estruturação do Manifest e Filtragem Precoce\n",
    "\n",
    "Diferente da versão DICOM original, os arquivos do Kaggle já possuem caminhos de imagem mapeados em CSVs simplificados. A primeira etapa é a criação de um \"Master Manifest\" para evitar o processamento de dados irrelevantes.\n",
    "\n",
    "- **Ação:** Consolidar os arquivos `calc_case(with_jpg_img).csv` e `mass_case(with_jpg_img).csv`.\n",
    "- **Filtro de Exclusão:** Remover imediatamente todos os registros rotulados como `BENIGN_WITHOUT_CALLBACK`. Esta classe representa achados que não exigem conduta clínica imediata e sua exclusão precoce economiza cerca de 20% do tempo de processamento total .\n",
    "- **Saída Esperada:** Um arquivo CSV único contendo as colunas `patient_id`, `image_path`, `mask_path`, `view` (CC/MLO) e o rótulo binário final (0 para Benigno, 1 para Maligno).\n",
    "\n",
    "## 2. Normalização de Intensidade (8-bit para Float32)\n",
    "\n",
    "Como os dados já foram convertidos para 8 bits, o objetivo é garantir que a rede neural receba uma distribuição estatística estável.\n",
    "\n",
    "- **Ação:** Converter a imagem carregada para o tipo `float32` e normalizar os pixels para o intervalo [0.0, 1.0].\n",
    "- **Justificativa:** Redes neurais convergem mais rapidamente quando os inputs estão centrados e escalonados, minimizando o risco de desaparecimento de gradiente em arquiteturas profundas como a U-Net .\n",
    "\n",
    "## 3. Isolamento Anatômico (Máscara do Seio)\n",
    "\n",
    "As digitalizações do DDSM contêm bordas ruidosas e etiquetas de texto (\"L\", \"CC\", \"R\") que introduzem viés de aprendizado (overfitting).\n",
    "\n",
    "- **Ação:** Aplicar o **Método de Otsu** para binarizar a imagem e identificar o maior objeto conectado (a mama).\n",
    "- **Refino:** Utilizar operações morfológicas de abertura para suavizar o contorno e aplicar uma máscara binária sobre a imagem original para transformar todo o fundo e artefatos de texto em preto absoluto (0).\n",
    "- **Saída Esperada:** Imagem em tons de cinza onde apenas o tecido mamário possui valores de pixel positivos.\n",
    "\n",
    "## 4. Supressão de Músculo Peitoral (Vistas MLO)\n",
    "\n",
    "O músculo peitoral aparece como uma região de alta densidade que pode distorcer a normalização do contraste local e mimetizar massas malignas.\n",
    "\n",
    "- **Ação:** Para imagens identificadas como vista MLO, aplicar a **Transformada de Hough** para detectar a borda linear do músculo no canto superior.\n",
    "- **Processamento:** Zerar (valor 0) todos os pixels contidos no triângulo ou polígono que delimita o músculo detectado.9\n",
    "- **Saída Esperada:** Imagem anatômica limpa, livre de densidades musculares interferentes.\n",
    "\n",
    "## 5. Realce de Contraste Adaptativo (CLAHE)\n",
    "\n",
    "A compressão para 8 bits reduz a separação entre tons de cinza. O CLAHE é vital para recuperar a visibilidade de espículas e margens tumorais .\n",
    "\n",
    "- **Ação:** Aplicar o algoritmo CLAHE com um `clipLimit` de 2.0 e um `tileGridSize` de 8x8.\n",
    "- **Controle de Qualidade:** É obrigatório gerar visualizações comparativas automáticas nesta etapa. O realce excessivo pode gerar ruído que o modelo de segmentação pode confundir com calcificações.13\n",
    "\n",
    "## 6. Extração de Patches de Precisão\n",
    "\n",
    "O redimensionamento de mamografias completas para tamanhos pequenos (ex: 224x224) destrói informações de textura essenciais. O uso de patches preserva a resolução nativa da lesão.\n",
    "\n",
    "- **Ação:** Utilizar as máscaras binárias fornecidas pelo dataset para calcular o centroide da lesão.\n",
    "- **Recorte:** Extrair um patch de 598x598 pixels centrado na lesão. Caso a lesão esteja próxima à borda, aplicar _zero padding_ para manter a dimensão fixa .\n",
    "- **Saída Esperada:** Pares sincronizados de patches (Imagem e Máscara) prontos para alimentação direta no modelo.\n",
    "\n",
    "## 7. Estratégia de Balanceamento de Dados\n",
    "\n",
    "O desequilíbrio entre malignos e benignos no CBIS-DDSM exige uma abordagem proativa para evitar o viés da classe majoritária.\n",
    "\n",
    "- **Ação:** Implementar pesos de classe no cálculo da função de perda (Loss Function).\n",
    "- **Justificativa:** Isso garante que o erro em um caso maligno (Falso Negativo) seja mais penalizado do que o erro em um caso benigno.\n",
    "- **Testar com e sem.**\n",
    "\n",
    "## 8. Aumento de Dados (Augmentation)\n",
    "\n",
    "A ideia é simular a variabilidade física do exame de mamografia para aumentar a generalização do modelo.\n",
    "\n",
    "- **Ação:** Aplicar **Deformações Elásticas** (Elastic Transforms) em conjunto com rotações aleatórias (até 175°) e espelhamentos (flips).\n",
    "- **Justificativa:** Como o tecido mamário é não rígido, as deformações elásticas simulam diferentes níveis de compressão mamária, tornando o modelo resiliente a variações de aquisição ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from typing import Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "class CBISDDSM_Preprocessor:\n",
    "    \n",
    "    def __init__(self, base_path='/kaggle/input/cbis-ddsm-breast-cancer-image-dataset', \n",
    "                 output_path='/kaggle/working'):\n",
    "        self.base_path = base_path\n",
    "        self.output_path = output_path\n",
    "        self.manifest = None\n",
    "    \n",
    "    # 1. Manifesting Structuration and Pre Filtering\n",
    "    def load_and_filter_manifest(self):\n",
    "        \"\"\"\n",
    "        Loads, consolidates, filters and saves the manifest assuring the correct filepaths.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered manifest with correct paths and labels.\n",
    "        \"\"\"\n",
    "        print(\">> Loading CSV files and consolidating Manifest...\")\n",
    "\n",
    "        # 1. Load diagnose CSVs and dicom_info (contains correct JPEG image paths)\n",
    "        try:\n",
    "            calc_df = pd.read_csv(f'{self.base_path}/csv/calc_case_description_train_set.csv')\n",
    "            mass_df = pd.read_csv(f'{self.base_path}/csv/mass_case_description_train_set.csv')\n",
    "            dicom_info = pd.read_csv(f'{self.base_path}/csv/dicom_info.csv')\n",
    "        except FileNotFoundError:\n",
    "            print(f'ERROR: Files not found in {self.base_path}')\n",
    "            return None\n",
    "\n",
    "        # 2. Merge both diagnose datasets\n",
    "        full_df = pd.concat([calc_df, mass_df], ignore_index=True)\n",
    "        \n",
    "        # 3. Clean dicom_info filepaths\n",
    "        dicom_info['image_path_clean'] = dicom_info['image_path'].str.replace('CBIS-DDSM/', '', regex=False)\n",
    "\n",
    "        # 4. Filter by image type in dicom_info\n",
    "        full_mamo_info = dicom_info[dicom_info['SeriesDescription'] == 'full mammogram images']\n",
    "        roi_mask_info = dicom_info[dicom_info['SeriesDescription'] == 'ROI mask images']\n",
    "\n",
    "        # 5. Create mapping dictionaries: PatientID (key) -> Filepaths (value)\n",
    "        img_map = dict(zip(full_mamo_info['PatientID'], full_mamo_info['image_path_clean']))\n",
    "        mask_map = dict(zip(roi_mask_info['PatientID'], roi_mask_info['image_path_clean']))\n",
    "\n",
    "        # 6. Extract keys (directory ID) from the original CSV paths\n",
    "        full_df['img_key'] = full_df['image file path'].str.split('/').str[0]\n",
    "        full_df['mask_key'] = full_df['ROI mask file path'].str.split('/').str[0]\n",
    "\n",
    "        # 7. Map real paths using filtered keys\n",
    "        full_df['image_path'] = full_df['img_key'].map(img_map)\n",
    "        full_df['mask_path'] = full_df['mask_key'].map(mask_map)\n",
    "        \n",
    "        # 8. Pathology and labels filtering\n",
    "        # Filter BENIGN_WITHOUT_CALLBACK data to focus on binary classification\n",
    "        full_df = full_df[full_df['pathology'] != 'BENIGN_WITHOUT_CALLBACK'].copy()\n",
    "        full_df['label'] = full_df['pathology'].apply(lambda x: 1 if x == 'MALIGNANT' else 0)\n",
    "\n",
    "        # 9. Remove rows where mapping has failed\n",
    "        initial_count = len(full_df)\n",
    "        self.manifest = full_df.dropna(subset=['image_path', 'mask_path']).copy()\n",
    "        print(f\"Mapping concluded: {len(self.manifest)} valid samples of {initial_count} initial ones.\")\n",
    "            \n",
    "        # 10. Final columns organization\n",
    "        self.manifest = self.manifest[[\n",
    "            'patient_id', 'image_path', 'mask_path', 'image view', 'label', 'abnormality type'\n",
    "        ]].rename(columns={'image view': 'view', 'abnormality type': 'abnormality_type'})\n",
    "\n",
    "        # 11. Saves final file\n",
    "        self.manifest = self.manifest.reset_index(drop=True)\n",
    "        save_loc = os.path.join(self.output_path, 'manifest.csv')\n",
    "        self.manifest.to_csv(save_loc, index=False)\n",
    "\n",
    "        # 12. Prints statistics\n",
    "        self.print_dataset_statistics()\n",
    "        \n",
    "        return self.manifest\n",
    "\n",
    "    def print_dataset_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculates and prints out dataset statistics.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\">> Calculating and printing statistics...\")\n",
    "        \n",
    "        if self.manifest is None: return\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Dataset Statistics:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Number of samples: {len(self.manifest)}\")\n",
    "        print(f\"\\nClass Distribution:\\n{self.manifest['label'].value_counts()}\")\n",
    "        print(f\"\\nAbnormality types:\\n{self.manifest['abnormality_type'].value_counts()}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Intensity normalization & Full Pipeline Execution\n",
    "    def read_and_normalize_image(self, image_rel_path: str, view: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Loads image and runs the full cleaning pipeline:\n",
    "        Load -> Float32 -> Otsu -> Muscle Suppression.\n",
    "\n",
    "        Args:\n",
    "            image_rel_path (str): Relative path to the image.\n",
    "            view (str): The view type ('CC' or 'MLO').\n",
    "        \n",
    "        Returns:\n",
    "            Optional[np.ndarray]: Normalized image array or None if not found.\n",
    "        \"\"\"\n",
    "        full_path = f\"{self.base_path}/{image_rel_path}\"\n",
    "        img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None: return None\n",
    "        \n",
    "        # 1. Normalize\n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # 2. Apply Otsu (Step 3)\n",
    "        img_otsu = self.segment_breast_otsu(img_float)\n",
    "        \n",
    "        # 3. Apply Muscle Suppression (Step 4)\n",
    "        img_final = self.suppress_pectoral_muscle(img_otsu, view)\n",
    "        \n",
    "        return img_final\n",
    "    \n",
    "    # 3. Anatomical Isolation (Breast Masking)\n",
    "    def segment_breast_otsu(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Uses Otsu's Thresholding to separate the foreground and keeps only\n",
    "        the largest connected component (the breast), removing labels and background noise.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Input image (float32 or uint8).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Image with clean background (absolute black) and normalized.\n",
    "        \"\"\"\n",
    "        # 1. Ensure image is 8-bit (required for cv2.threshold)\n",
    "        if image.dtype != np.uint8:\n",
    "            # If float [0,1], convert to [0,255]\n",
    "            img_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_uint8 = image\n",
    "\n",
    "        # 2. Apply Otsu's Thresholding\n",
    "        # cv2.THRESH_OTSU automatically calculates the optimal threshold value\n",
    "        thresh_val, binary_mask = cv2.threshold(img_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # 3. Morphological Operations (Refinement)\n",
    "        # Use 'Opening' (Erosion followed by Dilation) to remove small white noise dots\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # 4. Find Contours\n",
    "        # Returns all isolated white objects in the mask\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if not contours:\n",
    "            print(\">> Warning: No contours detected by Otsu.\")\n",
    "            return image  # Return original if segmentation fails critically\n",
    "\n",
    "        # 5. Select Largest Connected Component (The Breast)\n",
    "        # The largest contour by area is almost invariably the breast. The rest are labels.\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # 6. Create the Final Clean Mask\n",
    "        mask_clean = np.zeros_like(img_uint8)\n",
    "        # Fill the largest contour with white (255)\n",
    "        cv2.drawContours(mask_clean, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # 7. Apply Mask to Original Image\n",
    "        # Where mask is 0, the image becomes 0 (Absolute Black)\n",
    "        img_masked = cv2.bitwise_and(img_uint8, img_uint8, mask=mask_clean)\n",
    "\n",
    "        # Return normalized float32 [0.0, 1.0]\n",
    "        return img_masked.astype(np.float32) / 255.0\n",
    "    \n",
    "    def _is_breast_on_left(self, image: np.ndarray) -> bool:\n",
    "        \"\"\"\n",
    "        Helper to determine if the breast is on the left or right side of the image\n",
    "        by comparing the sum of pixel intensities in the left vs right halves.\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        left_sum = np.sum(image[:, :w//2])\n",
    "        right_sum = np.sum(image[:, w//2:])\n",
    "        return left_sum > right_sum\n",
    "\n",
    "    # 4. Pectoral Muscle Suppression (MLO Views)\n",
    "    def suppress_pectoral_muscle(self, image: np.ndarray, view: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        For MLO views, uses Hough Transform to detect the muscle edge and mask it out.\n",
    "        Extrapolates the detected muscle edge to the image boundaries\n",
    "        to ensure a clean 'corner cut' rather than a floating geometric shape.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Input image (float32 or uint8).\n",
    "            view (str): The view type ('CC' or 'MLO').\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Image with pectoral muscle masked (set to 0).\n",
    "        \"\"\"\n",
    "        # 0. Only apply to MLO views\n",
    "        if view != 'MLO':\n",
    "            return image\n",
    "\n",
    "        # 1. Prepare image for Edge Detection (uint8)\n",
    "        if image.dtype != np.uint8:\n",
    "            img_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_uint8 = image\n",
    "\n",
    "        # 2. Determine Orientation (Left or Right side)\n",
    "        is_left = self._is_breast_on_left(img_uint8)\n",
    "        h, w = img_uint8.shape\n",
    "\n",
    "        # 3. Canny Edge Detection\n",
    "        # We focus on the top half of the image where the muscle is located\n",
    "        edges = cv2.Canny(img_uint8, 30, 100)\n",
    "        \n",
    "        # Region of Interest (ROI): The muscle is always in the upper corner\n",
    "        # We mask out the bottom half to avoid detecting ribs or skin folds\n",
    "        roi_mask = np.zeros_like(edges)\n",
    "        if is_left:\n",
    "            roi_mask[0:h//2, 0:w//2] = 255 # Top-Left quadrant\n",
    "        else:\n",
    "            roi_mask[0:h//2, w//2:w] = 255 # Top-Right quadrant\n",
    "            \n",
    "        edges_roi = cv2.bitwise_and(edges, edges, mask=roi_mask)\n",
    "\n",
    "        # 4. Hough Transform to find lines\n",
    "        lines = cv2.HoughLinesP(\n",
    "            edges_roi, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=25, \n",
    "            minLineLength=30, \n",
    "            maxLineGap=30\n",
    "        )\n",
    "\n",
    "        if lines is None:\n",
    "            return image # No line found, return original\n",
    "\n",
    "        # 5. Filter for the \"Best\" Line (The Muscle Edge)\n",
    "        # The muscle edge is usually the longest line in that quadrant.\n",
    "        longest_line = None\n",
    "        max_len = 0\n",
    "\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if x2 == x1: continue \n",
    "            \n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "            \n",
    "            # Muscle is roughly diagonal (20-85 degrees)\n",
    "            if 20 < angle < 85 and length > max_len:\n",
    "                max_len = length\n",
    "                best_line = (x1, y1, x2, y2)\n",
    "\n",
    "        if best_line is None: return image\n",
    "\n",
    "        # Extrapolate Line to Edges\n",
    "        # y = mx + b\n",
    "        x1, y1, x2, y2 = best_line\n",
    "        m = (y2 - y1) / (x2 - x1)\n",
    "        b = y1 - m * x1\n",
    "\n",
    "        mask = np.zeros_like(img_uint8)\n",
    "        \n",
    "        if is_left:\n",
    "            # Muscle is Top-Left. We need points where line hits Top (y=0) and Left (x=0)\n",
    "            # 1. x-intercept (where y=0): x = -b/m\n",
    "            x_int = int(-b / m) if m != 0 else 0\n",
    "            # 2. y-intercept (where x=0): y = b\n",
    "            y_int = int(b)\n",
    "            \n",
    "            # Define Triangle: (0,0), (0, y_int), (x_int, 0)\n",
    "            # Clip to valid coordinates to be safe\n",
    "            pts = np.array([[[0, 0], [0, min(y_int, h)], [min(x_int, w), 0]]], dtype=np.int32)\n",
    "        \n",
    "        else:\n",
    "            # Muscle is Top-Right. We need points where line hits Top (y=0) and Right (x=W)\n",
    "            # 1. x-intercept (where y=0): x = -b/m\n",
    "            x_int = int(-b / m) if m != 0 else w\n",
    "            # 2. y-intercept (where x=W): y = mW + b\n",
    "            y_int = int(m * w + b)\n",
    "            \n",
    "            # Define Triangle: (W,0), (W, y_int), (x_int, 0)\n",
    "            pts = np.array([[[w, 0], [w, min(y_int, h)], [min(x_int, w), 0]]], dtype=np.int32)\n",
    "\n",
    "        # 6. Draw and Invert Mask\n",
    "        cv2.fillPoly(mask, pts, 255)\n",
    "        \n",
    "        # Keep everything NOT in the mask\n",
    "        img_no_muscle = cv2.bitwise_and(img_uint8, img_uint8, mask=cv2.bitwise_not(mask))\n",
    "        \n",
    "        return img_no_muscle.astype(np.float32) / 255.0\n",
    "\n",
    "    def read_mask(self, mask_rel_path: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Reads and binarizes the mask image.\n",
    "\n",
    "        Args:\n",
    "            mask_rel_path (str): Relative path to the mask image.\n",
    "        \n",
    "        Returns:\n",
    "            Optional[np.ndarray]: Binarized mask array or None if not found.\n",
    "        \"\"\"\n",
    "\n",
    "        full_path = f\"{self.base_path}/{mask_rel_path}\"\n",
    "        mask = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if mask is None: return None\n",
    "        # Binarization\n",
    "        _, mask_binary = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        return (mask_binary / 255.0).astype(np.float32)\n",
    "\n",
    "    # 5. Contrast Enhancement (CLAHE)\n",
    "    def apply_clahe(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance image contrast.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Input image array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: CLAHE enhanced image array.\n",
    "        \"\"\"\n",
    "        img_uint8 = (image * 255).astype(np.uint8)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(img_uint8).astype(np.float32) / 255.0\n",
    "\n",
    "    # 6. Precision Patch Extraction\n",
    "    def extract_lesion_patch(self, image: np.ndarray, mask: np.ndarray, patch_size=598):\n",
    "        \"\"\"\n",
    "        Calculates the center of the lesion based on the mask and extracts\n",
    "        a fixed-size patch. Applies Zero-Padding if the lesion is near the edge.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Full normalized image (float32).\n",
    "            mask (np.ndarray): Full binary mask (float32).\n",
    "            patch_size (int): Target size (default 598x598).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: (Image Patch, Mask Patch).\n",
    "        \"\"\"\n",
    "        # 1. Find the Center of the Lesion (Centroid)\n",
    "        # We convert mask to uint8 for cv2.moments\n",
    "        mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "        moments = cv2.moments(mask_uint8)\n",
    "\n",
    "        # Safety check: if mask is empty, fallback to image center\n",
    "        if moments[\"m00\"] == 0:\n",
    "            cy, cx = image.shape[0] // 2, image.shape[1] // 2\n",
    "        else:\n",
    "            cx = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "            cy = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "\n",
    "        # 2. Calculate Padding\n",
    "        # We pad the ORIGINAL image with half the patch size on all sides.\n",
    "        # This simplifies the math: we can simply slice without worrying about\n",
    "        # negative indices or going out of bounds.\n",
    "        half_size = patch_size // 2\n",
    "        \n",
    "        # Pad: ((top, bottom), (left, right))\n",
    "        # Constant values=0 means black padding\n",
    "        pad_width = ((half_size, half_size), (half_size, half_size))\n",
    "        \n",
    "        img_padded = np.pad(image, pad_width, mode='constant', constant_values=0)\n",
    "        mask_padded = np.pad(mask, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "        # 3. Calculate Coordinates in the Padded Image\n",
    "        # The center (cx, cy) in original moves to (cx+half, cy+half) in padded\n",
    "        pad_cx = cx + half_size\n",
    "        pad_cy = cy + half_size\n",
    "\n",
    "        # Determine start and end points for the crop\n",
    "        start_x = pad_cx - half_size\n",
    "        end_x = start_x + patch_size\n",
    "        start_y = pad_cy - half_size\n",
    "        end_y = start_y + patch_size\n",
    "\n",
    "        # 4. Perform the Crop\n",
    "        img_patch = img_padded[start_y:end_y, start_x:end_x]\n",
    "        mask_patch = mask_padded[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        # Final sanity check on shape\n",
    "        if img_patch.shape != (patch_size, patch_size):\n",
    "            img_patch = cv2.resize(img_patch, (patch_size, patch_size))\n",
    "            mask_patch = cv2.resize(mask_patch, (patch_size, patch_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        return img_patch, mask_patch\n",
    "    \n",
    "    # 7. Data Balancing Strategy\n",
    "    def compute_class_weights(self, train_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates class weights to penalize errors on the minority class\n",
    "        more heavily during the Loss Function calculation.\n",
    "\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): DataFrame containing only TRAINING data.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary mapping class index -> weight (e.g., {0: 1.0, 1: 2.5}).\n",
    "        \"\"\"\n",
    "        # Extract labels (0 = Benign, 1 = Malignant)\n",
    "        y_train = train_df['label'].values\n",
    "\n",
    "        # Calculate weights using sklearn's 'balanced' heuristic\n",
    "        # Formula: n_samples / (n_classes * np.bincount(y))\n",
    "        weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        # Create dictionary for easy usage in PyTorch/Keras\n",
    "        weight_dict = dict(zip(np.unique(y_train), weights))\n",
    "        \n",
    "        print(f\"\\n>> Class Weights Calculated:\")\n",
    "        print(f\"   Benign (0): {weight_dict[0]:.4f}\")\n",
    "        print(f\"   Malignant (1): {weight_dict[1]:.4f}\")\n",
    "        \n",
    "        return weight_dict\n",
    "    \n",
    "    # 8. Data Augmentation Pipeline\n",
    "    def get_augmentation_pipeline(self):\n",
    "        \"\"\"\n",
    "        Defines the sequence of geometric transformations to simulate\n",
    "        physical variations in mammograms. \n",
    "        Adjusted for compatibility with newer Albumentations versions.\n",
    "        \"\"\"\n",
    "        return A.Compose([\n",
    "            # 1. Flips\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "\n",
    "            # 2. Random Rotations\n",
    "            # border_mode=0 (cv2.BORDER_CONSTANT) automatically pads with 0 (black)\n",
    "            A.Rotate(limit=175, border_mode=0, p=0.5),\n",
    "\n",
    "            # 3. Elastic Transforms\n",
    "            # Removed 'alpha_affine', 'value', and 'mask_value' which caused errors.\n",
    "            A.ElasticTransform(\n",
    "                alpha=120, \n",
    "                sigma=120 * 0.05, \n",
    "                border_mode=0, \n",
    "                p=0.5\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def apply_augmentation(self, image: np.ndarray, mask: np.ndarray):\n",
    "        \"\"\"\n",
    "        Applies the augmentation pipeline to a pair of Image and Mask.\n",
    "        \n",
    "        Args:\n",
    "            image (np.ndarray): Input image patch.\n",
    "            mask (np.ndarray): Input mask patch.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Augmented image and mask.\n",
    "        \"\"\"\n",
    "        aug_pipeline = self.get_augmentation_pipeline()\n",
    "        \n",
    "        # Albumentations expects specific keys\n",
    "        augmented = aug_pipeline(image=image, mask=mask)\n",
    "        \n",
    "        return augmented['image'], augmented['mask']\n",
    "\n",
    "    def create_stratified_split(self, test_size=0.15, val_size=0.15):\n",
    "        \"\"\"\n",
    "        Creates stratified train, validation, and test splits.\n",
    "\n",
    "        Args:\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            val_size (float): Proportion of the dataset to include in the validation split.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]: Train, validation, and test DataFrames.\n",
    "        \"\"\"\n",
    "        train_val_df, test_df = train_test_split(\n",
    "            self.manifest, test_size=test_size, stratify=self.manifest['label'], random_state=42\n",
    "        )\n",
    "        val_ratio = val_size / (1 - test_size)\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_val_df, test_size=val_ratio, stratify=train_val_df['label'], random_state=42\n",
    "        )\n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    def visualize_sample(self, idx=0):\n",
    "        \"\"\"\n",
    "        Visualizes the full processing pipeline for a given sample index.\n",
    "        Plots 6 panels to compare phases.\n",
    "        \"\"\"\n",
    "        row = self.manifest.iloc[idx]\n",
    "        \n",
    "        # Load Raw\n",
    "        full_path = f\"{self.base_path}/{row['image_path']}\"\n",
    "        img_raw = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img_raw is None: return\n",
    "        img_raw_norm = img_raw.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Load Mask\n",
    "        mask = self.read_mask(row['mask_path'])\n",
    "        if mask.shape != img_raw_norm.shape:\n",
    "            mask = cv2.resize(mask, (img_raw_norm.shape[1], img_raw_norm.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Step 3: Otsu\n",
    "        img_otsu = self.segment_breast_otsu(img_raw_norm)\n",
    "        \n",
    "        # Step 4: Muscle Suppression\n",
    "        img_muscle = self.suppress_pectoral_muscle(img_otsu, row['view'])\n",
    "        \n",
    "        # Step 5: CLAHE\n",
    "        img_clahe = self.apply_clahe(img_muscle)\n",
    "        \n",
    "        # Step 6: Patch\n",
    "        img_patch, mask_patch = self.extract_lesion_patch(img_clahe, mask)\n",
    "        \n",
    "        # Step 8: Augmentation\n",
    "        img_aug, mask_aug = self.apply_augmentation(img_patch, mask_patch)\n",
    "        \n",
    "        # PLOTTING\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Row 1: Cleaning phases\n",
    "        axes[0,0].imshow(img_raw_norm, cmap='gray'); axes[0,0].set_title('1. Raw Image')\n",
    "        axes[0,1].imshow(img_otsu, cmap='gray'); axes[0,1].set_title('2. Otsu (Clean BG)')\n",
    "        axes[0,2].imshow(img_muscle, cmap='gray'); axes[0,2].set_title(f'3. Muscle Removed ({row[\"view\"]})')\n",
    "        \n",
    "        # Row 2: Enhancement & Patching\n",
    "        axes[1,0].imshow(img_clahe, cmap='gray'); axes[1,0].set_title('4. CLAHE Enhanced')\n",
    "        \n",
    "        # Overlay for Patch\n",
    "        overlay_patch = np.stack([img_patch]*3, axis=-1)\n",
    "        overlay_patch[:, :, 0] = np.where(mask_patch > 0.5, 1.0, overlay_patch[:, :, 0])\n",
    "        axes[1,1].imshow(overlay_patch); axes[1,1].set_title('5. Lesion Patch (598x598)')\n",
    "        \n",
    "        # Overlay for Augmentation\n",
    "        overlay_aug = np.stack([img_aug]*3, axis=-1)\n",
    "        overlay_aug[:, :, 0] = np.where(mask_aug > 0.5, 1.0, overlay_aug[:, :, 0])\n",
    "        axes[1,2].imshow(overlay_aug); axes[1,2].set_title('6. Augmented (+Elastic)')\n",
    "\n",
    "        plt.suptitle(f\"Processing Pipeline ID: {row['patient_id']} | Label: {row['label']}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_verification_batch(self, n_samples=20, save_dir='pipeline_verification'):\n",
    "        \"\"\"\n",
    "        Saves a batch of processed samples (plots) to disk for manual inspection.\n",
    "        \"\"\"\n",
    "        full_save_path = os.path.join(self.output_path, save_dir)\n",
    "        os.makedirs(full_save_path, exist_ok=True)\n",
    "        print(f\"\\n>> Generating {n_samples} verification images in: {full_save_path}\")\n",
    "\n",
    "        # Pick samples: Try to get 50% MLO (to check muscle) and 50% CC\n",
    "        mlo_indices = self.manifest[self.manifest['view'] == 'MLO'].index.tolist()\n",
    "        cc_indices = self.manifest[self.manifest['view'] == 'CC'].index.tolist()\n",
    "        \n",
    "        # Shuffle and select\n",
    "        random.shuffle(mlo_indices)\n",
    "        random.shuffle(cc_indices)\n",
    "        \n",
    "        # Combine indices (e.g., 10 MLO + 10 CC)\n",
    "        half_n = n_samples // 2\n",
    "        selected_indices = mlo_indices[:half_n] + cc_indices[:half_n]\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            self._save_single_sample(idx, full_save_path, i)\n",
    "            \n",
    "        print(f\">> Done. Check the '{save_dir}' folder.\")\n",
    "\n",
    "    def _save_single_sample(self, idx, save_folder, file_counter):\n",
    "        row = self.manifest.iloc[idx]\n",
    "        \n",
    "        # Pipeline Steps\n",
    "        full_path = f\"{self.base_path}/{row['image_path']}\"\n",
    "        img_raw = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img_raw is None: return\n",
    "        img_raw_norm = img_raw.astype(np.float32) / 255.0\n",
    "        \n",
    "        mask = self.read_mask(row['mask_path'])\n",
    "        if mask.shape != img_raw_norm.shape:\n",
    "            mask = cv2.resize(mask, (img_raw_norm.shape[1], img_raw_norm.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        img_otsu = self.segment_breast_otsu(img_raw_norm)\n",
    "        img_muscle = self.suppress_pectoral_muscle(img_otsu, row['view'])\n",
    "        img_clahe = self.apply_clahe(img_muscle)\n",
    "        img_patch, mask_patch = self.extract_lesion_patch(img_clahe, mask)\n",
    "        img_aug, mask_aug = self.apply_augmentation(img_patch, mask_patch)\n",
    "        \n",
    "        # Plotting\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        axes[0,0].imshow(img_raw_norm, cmap='gray'); axes[0,0].set_title(f'1. Raw ({row[\"view\"]})')\n",
    "        axes[0,1].imshow(img_otsu, cmap='gray'); axes[0,1].set_title('2. Otsu')\n",
    "        axes[0,2].imshow(img_muscle, cmap='gray'); axes[0,2].set_title('3. Muscle Removed')\n",
    "        axes[1,0].imshow(img_clahe, cmap='gray'); axes[1,0].set_title('4. CLAHE')\n",
    "        \n",
    "        overlay_patch = np.stack([img_patch]*3, axis=-1)\n",
    "        overlay_patch[:, :, 0] = np.where(mask_patch > 0.5, 1.0, overlay_patch[:, :, 0])\n",
    "        axes[1,1].imshow(overlay_patch); axes[1,1].set_title('5. Patch')\n",
    "        \n",
    "        overlay_aug = np.stack([img_aug]*3, axis=-1)\n",
    "        overlay_aug[:, :, 0] = np.where(mask_aug > 0.5, 1.0, overlay_aug[:, :, 0])\n",
    "        axes[1,2].imshow(overlay_aug); axes[1,2].set_title('6. Augmented')\n",
    "\n",
    "        plt.suptitle(f\"ID: {row['patient_id']} | Label: {row['label']} | View: {row['view']}\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # SAVE instead of Show\n",
    "        filename = f\"sample_{file_counter:02d}_{row['patient_id']}_{row['view']}.png\"\n",
    "        plt.savefig(os.path.join(save_folder, filename))\n",
    "        plt.close(fig) # Close memory to avoid overflow\n",
    "\n",
    "def run_pipeline():\n",
    "    processor = CBISDDSM_Preprocessor()\n",
    "    df = processor.load_and_filter_manifest()\n",
    "    \n",
    "    if df is not None:\n",
    "        train, val, test = processor.create_stratified_split()\n",
    "        print(f\"Split concluded: Train={len(train)}, Val={len(val)}, Test={len(test)}\")\n",
    "        \n",
    "        processor.compute_class_weights(train)\n",
    "        \n",
    "        print(\"\\n>> Validating pipeline steps on sample...\")\n",
    "\n",
    "        # EXECUTE BATCH SAVING\n",
    "        # Saves 20 images (10 MLO, 10 CC) to /kaggle/working/pipeline_verification/\n",
    "        processor.save_verification_batch(n_samples=20)\n",
    "\n",
    "        # EXECUTE MLO TEST\n",
    "        # Try to find an MLO sample to demonstrate muscle removal\n",
    "        \"\"\"\n",
    "        mlo_samples = df[df['view'] == 'MLO'].index\n",
    "        idx = mlo_samples[0] if len(mlo_samples) > 0 else 0\n",
    "        processor.visualize_sample(idx=idx)\n",
    "        \"\"\"\n",
    "\n",
    "    print(\"\\n>> Process finished...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
