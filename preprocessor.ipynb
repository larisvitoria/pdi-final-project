{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35540ae2",
   "metadata": {},
   "source": [
    "# **Development Guide: Modular Pre-Processing for Segmentation and Classification (CBIS-DDSM)**\n",
    "\n",
    "This outline defines the transformation steps to convert Kaggle JPEG images into high-fidelity tensors. The focus is on removing systematic noise and preserving critical morphological signals for distinguishing malignant from benign pathologies.\n",
    "\n",
    "## 1. Manifest Structuring and Early Filtering\n",
    "\n",
    "Unlike the original DICOM version, the Kaggle files already provide image paths mapped in simplified CSVs. The first step is to create a \"Master Manifest\" to avoid processing irrelevant data.\n",
    "\n",
    "- **Action:** Consolidate the files `calc_case(with_jpg_img).csv` and `mass_case(with_jpg_img).csv`.\n",
    "- **Exclusion Filter:** Immediately remove all records labeled `BENIGN_WITHOUT_CALLBACK`. This class represents findings that do not require immediate clinical action, and removing it early saves about 20% of total processing time.\n",
    "- **Expected Output:** A single CSV containing the columns `patient_id`, `image_path`, `mask_path`, `view` (CC/MLO), and the final binary label (0 for Benign, 1 for Malignant).\n",
    "\n",
    "## 2. Intensity Normalization (8-bit to Float32)\n",
    "\n",
    "Since the data is already converted to 8 bits, the goal is to ensure the neural network receives a stable statistical distribution.\n",
    "\n",
    "- **Action:** Convert the loaded image to `float32` and normalize pixels to the [0.0, 1.0] range.\n",
    "- **Justification:** Neural networks converge faster when inputs are centered and scaled, minimizing gradient vanishing in deep architectures like U-Net.\n",
    "\n",
    "## 3. Anatomical Isolation (Breast Masking)\n",
    "\n",
    "DDSM scans contain noisy borders and text labels (\"L\", \"CC\", \"R\") that introduce learning bias (overfitting).\n",
    "\n",
    "- **Action:** Apply the **Otsu Method** to binarize the image and identify the largest connected object (the breast).\n",
    "- **Refinement:** Use morphological opening to smooth the contour and apply a binary mask over the original image to turn all background and text artifacts to absolute black (0).\n",
    "- **Expected Output:** Grayscale image where only breast tissue has positive pixel values.\n",
    "\n",
    "## 4. Pectoral Muscle Suppression (MLO Views)\n",
    "\n",
    "The pectoral muscle appears as a high-density region that can distort local contrast normalization and mimic malignant masses.\n",
    "\n",
    "- **Action:** For images identified as MLO view, apply the **Hough Transform** to detect the linear muscle edge in the upper corner.\n",
    "- **Processing:** Zero out (value 0) all pixels inside the triangle or polygon that delimits the detected muscle.\n",
    "- **Expected Output:** Clean anatomical image, free of interfering muscle densities.\n",
    "\n",
    "## 5. Adaptive Contrast Enhancement (CLAHE)\n",
    "\n",
    "Compression to 8 bits reduces the separation between gray tones. CLAHE is vital to recover the visibility of spicules and tumor margins.\n",
    "\n",
    "- **Action:** Apply CLAHE with `clipLimit` 2.0 and `tileGridSize` 8x8.\n",
    "- **Quality Control:** It is mandatory to generate automatic comparative visualizations at this stage. Excessive enhancement can generate noise that the segmentation model may confuse with calcifications.\n",
    "\n",
    "## 6. Precision Patch Extraction\n",
    "\n",
    "Resizing full mammograms to small sizes (e.g., 224x224) destroys essential texture information. Using patches preserves native lesion resolution.\n",
    "\n",
    "- **Action:** Use the provided binary masks to compute the lesion centroid.\n",
    "- **Crop:** Extract a 598x598 patch centered on the lesion. If the lesion is near the edge, apply zero padding to keep a fixed dimension.\n",
    "- **Expected Output:** Synchronized patch pairs (Image and Mask) ready for direct model input.\n",
    "\n",
    "## 7. Data Balancing Strategy\n",
    "\n",
    "The imbalance between malignant and benign in CBIS-DDSM requires a proactive approach to avoid majority-class bias.\n",
    "\n",
    "- **Action:** Implement class weights in the loss function calculation.\n",
    "- **Justification:** This ensures errors on malignant cases (False Negatives) are penalized more than errors on benign cases.\n",
    "- **Test with and without.**\n",
    "\n",
    "## 8. Data Augmentation\n",
    "\n",
    "The idea is to simulate physical variability in mammography exams to increase model generalization.\n",
    "\n",
    "- **Action:** Apply **Elastic Transforms** along with random rotations (up to 175\u00b0) and flips.\n",
    "- **Justification:** Because breast tissue is non-rigid, elastic deformations simulate different compression levels, making the model resilient to acquisition variations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2d15d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading CSV files and consolidating Manifest...\n",
      "Mapping concluded: 2286 valid samples of 2286 initial ones.\n",
      ">> Calculating and printing statistics...\n",
      "\n",
      "==================================================\n",
      "Dataset Statistics:\n",
      "==================================================\n",
      "Number of samples: 2286\n",
      "\n",
      "Class Distribution:\n",
      "label\n",
      "1    1181\n",
      "0    1105\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Abnormality types:\n",
      "abnormality_type\n",
      "mass             1214\n",
      "calcification    1072\n",
      "Name: count, dtype: int64\n",
      "==================================================\n",
      "\n",
      "Split concluded: Train=1598, Val=344, Test=344\n",
      "\n",
      ">> Class Weights Calculated:\n",
      "   Benign (0): 1.0025\n",
      "   Malignant (1): 0.9975\n",
      "\n",
      ">> Validating pipeline steps on sample...\n",
      "\n",
      ">> Generating 20 verification images in: preprocessed_output/pipeline_verification\n",
      ">> Done. Check the 'pipeline_verification' folder.\n",
      "\n",
      ">> Process finished...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from typing import Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "class CBISDDSM_Preprocessor:\n",
    "    \n",
    "    def __init__(self, base_path=None, output_path=None):\n",
    "        default_kaggle = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset'\n",
    "        default_local = 'cbis-ddsm-breast-cancer-image-dataset'\n",
    "\n",
    "        if base_path is None:\n",
    "            candidate_paths = [\n",
    "                os.path.join(os.getcwd(), default_local),\n",
    "                default_local,\n",
    "                default_kaggle,\n",
    "            ]\n",
    "            for path in candidate_paths:\n",
    "                if os.path.isfile(os.path.join(path, 'csv', 'calc_case_description_train_set.csv')):\n",
    "                    base_path = path\n",
    "                    break\n",
    "            else:\n",
    "                base_path = default_local\n",
    "\n",
    "        if output_path is None:\n",
    "            output_path = '/kaggle/working' if os.path.isdir('/kaggle/working') else 'preprocessed_output'\n",
    "\n",
    "        self.base_path = base_path\n",
    "        self.output_path = output_path\n",
    "        self.manifest = None\n",
    "    \n",
    "    # 1. Manifesting Structuration and Pre Filtering\n",
    "    def load_and_filter_manifest(self):\n",
    "        \"\"\"\n",
    "        Loads, consolidates, filters and saves the manifest assuring the correct filepaths.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered manifest with correct paths and labels.\n",
    "        \"\"\"\n",
    "        print(\">> Loading CSV files and consolidating Manifest...\")\n",
    "\n",
    "        # 1. Load diagnose CSVs and dicom_info (contains correct JPEG image paths)\n",
    "        try:\n",
    "            calc_df = pd.read_csv(f'{self.base_path}/csv/calc_case_description_train_set.csv')\n",
    "            mass_df = pd.read_csv(f'{self.base_path}/csv/mass_case_description_train_set.csv')\n",
    "            dicom_info = pd.read_csv(f'{self.base_path}/csv/dicom_info.csv')\n",
    "        except FileNotFoundError:\n",
    "            print(f'ERROR: Files not found in {self.base_path}')\n",
    "            return None\n",
    "\n",
    "        # 2. Merge both diagnose datasets\n",
    "        full_df = pd.concat([calc_df, mass_df], ignore_index=True)\n",
    "        \n",
    "        # 3. Clean dicom_info filepaths\n",
    "        dicom_info['image_path_clean'] = dicom_info['image_path'].str.replace('CBIS-DDSM/', '', regex=False)\n",
    "\n",
    "        # 4. Filter by image type in dicom_info\n",
    "        full_mamo_info = dicom_info[dicom_info['SeriesDescription'] == 'full mammogram images']\n",
    "        roi_mask_info = dicom_info[dicom_info['SeriesDescription'] == 'ROI mask images']\n",
    "\n",
    "        # 5. Create mapping dictionaries: PatientID (key) -> Filepaths (value)\n",
    "        img_map = dict(zip(full_mamo_info['PatientID'], full_mamo_info['image_path_clean']))\n",
    "        mask_map = dict(zip(roi_mask_info['PatientID'], roi_mask_info['image_path_clean']))\n",
    "\n",
    "        # 6. Extract keys (directory ID) from the original CSV paths\n",
    "        full_df['img_key'] = full_df['image file path'].str.split('/').str[0]\n",
    "        full_df['mask_key'] = full_df['ROI mask file path'].str.split('/').str[0]\n",
    "\n",
    "        # 7. Map real paths using filtered keys\n",
    "        full_df['image_path'] = full_df['img_key'].map(img_map)\n",
    "        full_df['mask_path'] = full_df['mask_key'].map(mask_map)\n",
    "        \n",
    "        # 8. Pathology and labels filtering\n",
    "        # Filter BENIGN_WITHOUT_CALLBACK data to focus on binary classification\n",
    "        full_df = full_df[full_df['pathology'] != 'BENIGN_WITHOUT_CALLBACK'].copy()\n",
    "        full_df['label'] = full_df['pathology'].apply(lambda x: 1 if x == 'MALIGNANT' else 0)\n",
    "        full_df['participant_id'] = full_df['patient_id'].astype(str).str.extract(r'(P_\\d+)', expand=False)\n",
    "        full_df['participant_id'] = full_df['participant_id'].fillna(full_df['patient_id'].astype(str))\n",
    "\n",
    "        # 9. Remove rows where mapping has failed\n",
    "        initial_count = len(full_df)\n",
    "        self.manifest = full_df.dropna(subset=['image_path', 'mask_path']).copy()\n",
    "        print(f\"Mapping concluded: {len(self.manifest)} valid samples of {initial_count} initial ones.\")\n",
    "            \n",
    "        # 10. Final columns organization\n",
    "        self.manifest = self.manifest[[\n",
    "            'patient_id', 'participant_id', 'image_path', 'mask_path', 'image view', 'label', 'abnormality type'\n",
    "        ]].rename(columns={'image view': 'view', 'abnormality type': 'abnormality_type'})\n",
    "\n",
    "        # 11. Saves final file\n",
    "        self.manifest = self.manifest.reset_index(drop=True)\n",
    "        os.makedirs(self.output_path, exist_ok=True)\n",
    "        save_loc = os.path.join(self.output_path, 'manifest.csv')\n",
    "        self.manifest.to_csv(save_loc, index=False)\n",
    "\n",
    "        # 12. Prints statistics\n",
    "        self.print_dataset_statistics()\n",
    "        \n",
    "        return self.manifest\n",
    "\n",
    "    def print_dataset_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculates and prints out dataset statistics.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\">> Calculating and printing statistics...\")\n",
    "        \n",
    "        if self.manifest is None: return\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Dataset Statistics:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Number of samples: {len(self.manifest)}\")\n",
    "        print(f\"\\nClass Distribution:\\n{self.manifest['label'].value_counts()}\")\n",
    "        print(f\"\\nAbnormality types:\\n{self.manifest['abnormality_type'].value_counts()}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Intensity normalization & Full Pipeline Execution\n",
    "    def read_and_normalize_image(self, image_rel_path: str, view: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Loads image and runs the full cleaning pipeline:\n",
    "        Load -> Float32 -> Otsu -> Muscle Suppression.\n",
    "\n",
    "        Args:\n",
    "            image_rel_path (str): Relative path to the image.\n",
    "            view (str): The view type ('CC' or 'MLO').\n",
    "        \n",
    "        Returns:\n",
    "            Optional[np.ndarray]: Normalized image array or None if not found.\n",
    "        \"\"\"\n",
    "        full_path = f\"{self.base_path}/{image_rel_path}\"\n",
    "        img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None: return None\n",
    "        \n",
    "        # 1. Normalize\n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # 2. Apply Otsu (Step 3)\n",
    "        img_otsu = self.segment_breast_otsu(img_float)\n",
    "        \n",
    "        # 3. Apply Muscle Suppression (Step 4)\n",
    "        img_final = self.suppress_pectoral_muscle(img_otsu, view)\n",
    "        \n",
    "        return img_final\n",
    "    \n",
    "    # 3. Anatomical Isolation (Breast Masking)\n",
    "    def segment_breast_otsu(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Uses Otsu's Thresholding to separate the foreground and keeps only\n",
    "        the largest connected component (the breast), removing labels and background noise.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Input image (float32 or uint8).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Image with clean background (absolute black) and normalized.\n",
    "        \"\"\"\n",
    "        # 1. Ensure image is 8-bit (required for cv2.threshold)\n",
    "        if image.dtype != np.uint8:\n",
    "            # If float [0,1], convert to [0,255]\n",
    "            img_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_uint8 = image\n",
    "\n",
    "        # 2. Apply Otsu's Thresholding\n",
    "        # cv2.THRESH_OTSU automatically calculates the optimal threshold value\n",
    "        thresh_val, binary_mask = cv2.threshold(img_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # 3. Morphological Operations (Refinement)\n",
    "        # Use 'Opening' (Erosion followed by Dilation) to remove small white noise dots\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # 4. Find Contours\n",
    "        # Returns all isolated white objects in the mask\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if not contours:\n",
    "            print(\">> Warning: No contours detected by Otsu.\")\n",
    "            return image  # Return original if segmentation fails critically\n",
    "\n",
    "        # 5. Select Largest Connected Component (The Breast)\n",
    "        # The largest contour by area is almost invariably the breast. The rest are labels.\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # 6. Create the Final Clean Mask\n",
    "        mask_clean = np.zeros_like(img_uint8)\n",
    "        # Fill the largest contour with white (255)\n",
    "        cv2.drawContours(mask_clean, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # 7. Apply Mask to Original Image\n",
    "        # Where mask is 0, the image becomes 0 (Absolute Black)\n",
    "        img_masked = cv2.bitwise_and(img_uint8, img_uint8, mask=mask_clean)\n",
    "\n",
    "        # Return normalized float32 [0.0, 1.0]\n",
    "        return img_masked.astype(np.float32) / 255.0\n",
    "    \n",
    "    def _is_breast_on_left(self, image: np.ndarray) -> bool:\n",
    "        \"\"\"\n",
    "        Helper to determine if the breast is on the left or right side of the image\n",
    "        by comparing the sum of pixel intensities in the left vs right halves.\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        left_sum = np.sum(image[:, :w//2])\n",
    "        right_sum = np.sum(image[:, w//2:])\n",
    "        return left_sum > right_sum\n",
    "\n",
    "    # 4. Pectoral Muscle Suppression (MLO Views)\n",
    "    def suppress_pectoral_muscle(self, image: np.ndarray, view: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        For MLO views, uses Hough Transform to detect the muscle edge and mask it out.\n",
    "        Extrapolates the detected muscle edge to the image boundaries\n",
    "        to ensure a clean 'corner cut' rather than a floating geometric shape.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Input image (float32 or uint8).\n",
    "            view (str): The view type ('CC' or 'MLO').\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Image with pectoral muscle masked (set to 0).\n",
    "        \"\"\"\n",
    "        # 0. Only apply to MLO views\n",
    "        if view != 'MLO':\n",
    "            return image\n",
    "\n",
    "        # 1. Prepare image for Edge Detection (uint8)\n",
    "        if image.dtype != np.uint8:\n",
    "            img_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_uint8 = image\n",
    "\n",
    "        # 2. Determine Orientation (Left or Right side)\n",
    "        is_left = self._is_breast_on_left(img_uint8)\n",
    "        h, w = img_uint8.shape\n",
    "\n",
    "        # 3. Canny Edge Detection\n",
    "        # We focus on the top half of the image where the muscle is located\n",
    "        edges = cv2.Canny(img_uint8, 30, 100)\n",
    "        \n",
    "        # Region of Interest (ROI): The muscle is always in the upper corner\n",
    "        # We mask out the bottom half to avoid detecting ribs or skin folds\n",
    "        roi_mask = np.zeros_like(edges)\n",
    "        if is_left:\n",
    "            roi_mask[0:h//2, 0:w//2] = 255 # Top-Left quadrant\n",
    "        else:\n",
    "            roi_mask[0:h//2, w//2:w] = 255 # Top-Right quadrant\n",
    "            \n",
    "        edges_roi = cv2.bitwise_and(edges, edges, mask=roi_mask)\n",
    "\n",
    "        # 4. Hough Transform to find lines\n",
    "        lines = cv2.HoughLinesP(\n",
    "            edges_roi, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=25, \n",
    "            minLineLength=30, \n",
    "            maxLineGap=30\n",
    "        )\n",
    "\n",
    "        if lines is None:\n",
    "            return image # No line found, return original\n",
    "\n",
    "        # 5. Filter for the \"Best\" Line (The Muscle Edge)\n",
    "        # The muscle edge is usually the longest line in that quadrant.\n",
    "        longest_line = None\n",
    "        max_len = 0\n",
    "\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if x2 == x1: continue \n",
    "            \n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "            \n",
    "            # Muscle is roughly diagonal (20-85 degrees)\n",
    "            if 20 < angle < 85 and length > max_len:\n",
    "                max_len = length\n",
    "                best_line = (x1, y1, x2, y2)\n",
    "\n",
    "        if best_line is None: return image\n",
    "\n",
    "        # Extrapolate Line to Edges\n",
    "        # y = mx + b\n",
    "        x1, y1, x2, y2 = best_line\n",
    "        m = (y2 - y1) / (x2 - x1)\n",
    "        b = y1 - m * x1\n",
    "\n",
    "        mask = np.zeros_like(img_uint8)\n",
    "        \n",
    "        if is_left:\n",
    "            # Muscle is Top-Left. We need points where line hits Top (y=0) and Left (x=0)\n",
    "            # 1. x-intercept (where y=0): x = -b/m\n",
    "            x_int = int(-b / m) if m != 0 else 0\n",
    "            # 2. y-intercept (where x=0): y = b\n",
    "            y_int = int(b)\n",
    "            \n",
    "            # Define Triangle: (0,0), (0, y_int), (x_int, 0)\n",
    "            # Clip to valid coordinates to be safe\n",
    "            pts = np.array([[[0, 0], [0, min(y_int, h)], [min(x_int, w), 0]]], dtype=np.int32)\n",
    "        \n",
    "        else:\n",
    "            # Muscle is Top-Right. We need points where line hits Top (y=0) and Right (x=W)\n",
    "            # 1. x-intercept (where y=0): x = -b/m\n",
    "            x_int = int(-b / m) if m != 0 else w\n",
    "            # 2. y-intercept (where x=W): y = mW + b\n",
    "            y_int = int(m * w + b)\n",
    "            \n",
    "            # Define Triangle: (W,0), (W, y_int), (x_int, 0)\n",
    "            pts = np.array([[[w, 0], [w, min(y_int, h)], [min(x_int, w), 0]]], dtype=np.int32)\n",
    "\n",
    "        # 6. Draw and Invert Mask\n",
    "        cv2.fillPoly(mask, pts, 255)\n",
    "        \n",
    "        # Keep everything NOT in the mask\n",
    "        img_no_muscle = cv2.bitwise_and(img_uint8, img_uint8, mask=cv2.bitwise_not(mask))\n",
    "        \n",
    "        return img_no_muscle.astype(np.float32) / 255.0\n",
    "\n",
    "    def read_mask(self, mask_rel_path: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Reads and binarizes the mask image.\n",
    "\n",
    "        Args:\n",
    "            mask_rel_path (str): Relative path to the mask image.\n",
    "        \n",
    "        Returns:\n",
    "            Optional[np.ndarray]: Binarized mask array or None if not found.\n",
    "        \"\"\"\n",
    "\n",
    "        full_path = f\"{self.base_path}/{mask_rel_path}\"\n",
    "        mask = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if mask is None: return None\n",
    "        # Binarization\n",
    "        _, mask_binary = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        return (mask_binary / 255.0).astype(np.float32)\n",
    "\n",
    "    # 5. Contrast Enhancement (CLAHE)\n",
    "    def apply_clahe(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance image contrast.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Input image array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: CLAHE enhanced image array.\n",
    "        \"\"\"\n",
    "        img_uint8 = (image * 255).astype(np.uint8)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(img_uint8).astype(np.float32) / 255.0\n",
    "\n",
    "    # 6. Precision Patch Extraction\n",
    "    def extract_lesion_patch(self, image: np.ndarray, mask: np.ndarray, patch_size=598):\n",
    "        \"\"\"\n",
    "        Calculates the center of the lesion based on the mask and extracts\n",
    "        a fixed-size patch. Applies Zero-Padding if the lesion is near the edge.\n",
    "\n",
    "        Args:\n",
    "            image (np.ndarray): Full normalized image (float32).\n",
    "            mask (np.ndarray): Full binary mask (float32).\n",
    "            patch_size (int): Target size (default 598x598).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: (Image Patch, Mask Patch).\n",
    "        \"\"\"\n",
    "        # 1. Find the Center of the Lesion (Centroid)\n",
    "        # We convert mask to uint8 for cv2.moments\n",
    "        mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "        moments = cv2.moments(mask_uint8)\n",
    "\n",
    "        # Safety check: if mask is empty, fallback to image center\n",
    "        if moments[\"m00\"] == 0:\n",
    "            cy, cx = image.shape[0] // 2, image.shape[1] // 2\n",
    "        else:\n",
    "            cx = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "            cy = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "\n",
    "        # 2. Calculate Padding\n",
    "        # We pad the ORIGINAL image with half the patch size on all sides.\n",
    "        # This simplifies the math: we can simply slice without worrying about\n",
    "        # negative indices or going out of bounds.\n",
    "        half_size = patch_size // 2\n",
    "        \n",
    "        # Pad: ((top, bottom), (left, right))\n",
    "        # Constant values=0 means black padding\n",
    "        pad_width = ((half_size, half_size), (half_size, half_size))\n",
    "        \n",
    "        img_padded = np.pad(image, pad_width, mode='constant', constant_values=0)\n",
    "        mask_padded = np.pad(mask, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "        # 3. Calculate Coordinates in the Padded Image\n",
    "        # The center (cx, cy) in original moves to (cx+half, cy+half) in padded\n",
    "        pad_cx = cx + half_size\n",
    "        pad_cy = cy + half_size\n",
    "\n",
    "        # Determine start and end points for the crop\n",
    "        start_x = pad_cx - half_size\n",
    "        end_x = start_x + patch_size\n",
    "        start_y = pad_cy - half_size\n",
    "        end_y = start_y + patch_size\n",
    "\n",
    "        # 4. Perform the Crop\n",
    "        img_patch = img_padded[start_y:end_y, start_x:end_x]\n",
    "        mask_patch = mask_padded[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        # Final sanity check on shape\n",
    "        if img_patch.shape != (patch_size, patch_size):\n",
    "            img_patch = cv2.resize(img_patch, (patch_size, patch_size))\n",
    "            mask_patch = cv2.resize(mask_patch, (patch_size, patch_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        return img_patch, mask_patch\n",
    "    \n",
    "    # 7. Data Balancing Strategy\n",
    "    def compute_class_weights(self, train_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates class weights to penalize errors on the minority class\n",
    "        more heavily during the Loss Function calculation.\n",
    "\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): DataFrame containing only TRAINING data.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary mapping class index -> weight (e.g., {0: 1.0, 1: 2.5}).\n",
    "        \"\"\"\n",
    "        # Extract labels (0 = Benign, 1 = Malignant)\n",
    "        y_train = train_df['label'].values\n",
    "\n",
    "        # Calculate weights using sklearn's 'balanced' heuristic\n",
    "        # Formula: n_samples / (n_classes * np.bincount(y))\n",
    "        weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        # Create dictionary for easy usage in PyTorch/Keras\n",
    "        weight_dict = dict(zip(np.unique(y_train), weights))\n",
    "        \n",
    "        print(f\"\\n>> Class Weights Calculated:\")\n",
    "        print(f\"   Benign (0): {weight_dict[0]:.4f}\")\n",
    "        print(f\"   Malignant (1): {weight_dict[1]:.4f}\")\n",
    "        \n",
    "        return weight_dict\n",
    "    \n",
    "    # 8. Data Augmentation Pipeline\n",
    "    def get_augmentation_pipeline(self):\n",
    "        \"\"\"\n",
    "        Defines the sequence of geometric transformations to simulate\n",
    "        physical variations in mammograms. \n",
    "        Adjusted for compatibility with newer Albumentations versions.\n",
    "        \"\"\"\n",
    "        return A.Compose([\n",
    "            # 1. Flips\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "\n",
    "            # 2. Random Rotations\n",
    "            # border_mode=0 (cv2.BORDER_CONSTANT) automatically pads with 0 (black)\n",
    "            A.Rotate(limit=175, border_mode=0, p=0.5),\n",
    "\n",
    "            # 3. Elastic Transforms\n",
    "            # Removed 'alpha_affine', 'value', and 'mask_value' which caused errors.\n",
    "            A.ElasticTransform(\n",
    "                alpha=120, \n",
    "                sigma=120 * 0.05, \n",
    "                border_mode=0, \n",
    "                p=0.5\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def apply_augmentation(self, image: np.ndarray, mask: np.ndarray):\n",
    "        \"\"\"\n",
    "        Applies the augmentation pipeline to a pair of Image and Mask.\n",
    "        \n",
    "        Args:\n",
    "            image (np.ndarray): Input image patch.\n",
    "            mask (np.ndarray): Input mask patch.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Augmented image and mask.\n",
    "        \"\"\"\n",
    "        aug_pipeline = self.get_augmentation_pipeline()\n",
    "        \n",
    "        # Albumentations expects specific keys\n",
    "        augmented = aug_pipeline(image=image, mask=mask)\n",
    "\n",
    "        img_out = augmented['image'].astype(np.float32)\n",
    "        mask_out = (augmented['mask'] > 0.5).astype(np.float32)\n",
    "        return img_out, mask_out\n",
    "\n",
    "    def create_group_split(self, test_size=0.15, val_size=0.15, group_col='participant_id'):\n",
    "        \"\"\"\n",
    "        Creates group-aware train, validation, and test splits to avoid leakage.\n",
    "\n",
    "        Args:\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            val_size (float): Proportion of the dataset to include in the validation split.\n",
    "            group_col (str): Column name used to group samples (e.g., participant_id).\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]: Train, validation, and test DataFrames.\n",
    "        \"\"\"\n",
    "        if group_col not in self.manifest.columns:\n",
    "            raise ValueError(f\"Missing group column: {group_col}\")\n",
    "\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "        train_val_idx, test_idx = next(gss.split(self.manifest, groups=self.manifest[group_col]))\n",
    "        train_val_df = self.manifest.iloc[train_val_idx].reset_index(drop=True)\n",
    "        test_df = self.manifest.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "        val_ratio = val_size / (1 - test_size)\n",
    "        gss_val = GroupShuffleSplit(n_splits=1, test_size=val_ratio, random_state=42)\n",
    "        train_idx, val_idx = next(gss_val.split(train_val_df, groups=train_val_df[group_col]))\n",
    "        train_df = train_val_df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = train_val_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    def visualize_sample(self, idx=0):\n",
    "        \"\"\"\n",
    "        Visualizes the full processing pipeline for a given sample index.\n",
    "        Plots 6 panels to compare phases.\n",
    "        \"\"\"\n",
    "        row = self.manifest.iloc[idx]\n",
    "        \n",
    "        # Load Raw\n",
    "        full_path = f\"{self.base_path}/{row['image_path']}\"\n",
    "        img_raw = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img_raw is None: return\n",
    "        img_raw_norm = img_raw.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Load Mask\n",
    "        mask = self.read_mask(row['mask_path'])\n",
    "        if mask.shape != img_raw_norm.shape:\n",
    "            mask = cv2.resize(mask, (img_raw_norm.shape[1], img_raw_norm.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Step 3: Otsu\n",
    "        img_otsu = self.segment_breast_otsu(img_raw_norm)\n",
    "        \n",
    "        # Step 4: Muscle Suppression\n",
    "        img_muscle = self.suppress_pectoral_muscle(img_otsu, row['view'])\n",
    "        \n",
    "        # Step 5: CLAHE\n",
    "        img_clahe = self.apply_clahe(img_muscle)\n",
    "        \n",
    "        # Step 6: Patch\n",
    "        img_patch, mask_patch = self.extract_lesion_patch(img_clahe, mask)\n",
    "        \n",
    "        # Step 8: Augmentation\n",
    "        img_aug, mask_aug = self.apply_augmentation(img_patch, mask_patch)\n",
    "        \n",
    "        # PLOTTING\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Row 1: Cleaning phases\n",
    "        axes[0,0].imshow(img_raw_norm, cmap='gray'); axes[0,0].set_title('1. Raw Image')\n",
    "        axes[0,1].imshow(img_otsu, cmap='gray'); axes[0,1].set_title('2. Otsu (Clean BG)')\n",
    "        axes[0,2].imshow(img_muscle, cmap='gray'); axes[0,2].set_title(f'3. Muscle Removed ({row[\"view\"]})')\n",
    "        \n",
    "        # Row 2: Enhancement & Patching\n",
    "        axes[1,0].imshow(img_clahe, cmap='gray'); axes[1,0].set_title('4. CLAHE Enhanced')\n",
    "        \n",
    "        # Overlay for Patch\n",
    "        overlay_patch = np.stack([img_patch]*3, axis=-1)\n",
    "        overlay_patch[:, :, 0] = np.where(mask_patch > 0.5, 1.0, overlay_patch[:, :, 0])\n",
    "        axes[1,1].imshow(overlay_patch); axes[1,1].set_title('5. Lesion Patch (598x598)')\n",
    "        \n",
    "        # Overlay for Augmentation\n",
    "        overlay_aug = np.stack([img_aug]*3, axis=-1)\n",
    "        overlay_aug[:, :, 0] = np.where(mask_aug > 0.5, 1.0, overlay_aug[:, :, 0])\n",
    "        axes[1,2].imshow(overlay_aug); axes[1,2].set_title('6. Augmented (+Elastic)')\n",
    "\n",
    "        plt.suptitle(f\"Processing Pipeline ID: {row['patient_id']} | Label: {row['label']}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_verification_batch(self, n_samples=20, save_dir='pipeline_verification'):\n",
    "        \"\"\"\n",
    "        Saves a batch of processed samples (plots) to disk for manual inspection.\n",
    "        \"\"\"\n",
    "        full_save_path = os.path.join(self.output_path, save_dir)\n",
    "        os.makedirs(full_save_path, exist_ok=True)\n",
    "        print(f\"\\n>> Generating {n_samples} verification images in: {full_save_path}\")\n",
    "\n",
    "        # Pick samples: Try to get 50% MLO (to check muscle) and 50% CC\n",
    "        mlo_indices = self.manifest[self.manifest['view'] == 'MLO'].index.tolist()\n",
    "        cc_indices = self.manifest[self.manifest['view'] == 'CC'].index.tolist()\n",
    "        \n",
    "        # Shuffle and select\n",
    "        random.shuffle(mlo_indices)\n",
    "        random.shuffle(cc_indices)\n",
    "        \n",
    "        # Combine indices (e.g., 10 MLO + 10 CC)\n",
    "        half_n = n_samples // 2\n",
    "        selected_indices = mlo_indices[:half_n] + cc_indices[:half_n]\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            self._save_single_sample(idx, full_save_path, i)\n",
    "            \n",
    "        print(f\">> Done. Check the '{save_dir}' folder.\")\n",
    "\n",
    "    def _save_single_sample(self, idx, save_folder, file_counter):\n",
    "        row = self.manifest.iloc[idx]\n",
    "        \n",
    "        # Pipeline Steps\n",
    "        full_path = f\"{self.base_path}/{row['image_path']}\"\n",
    "        img_raw = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img_raw is None: return\n",
    "        img_raw_norm = img_raw.astype(np.float32) / 255.0\n",
    "        \n",
    "        mask = self.read_mask(row['mask_path'])\n",
    "        if mask.shape != img_raw_norm.shape:\n",
    "            mask = cv2.resize(mask, (img_raw_norm.shape[1], img_raw_norm.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        img_otsu = self.segment_breast_otsu(img_raw_norm)\n",
    "        img_muscle = self.suppress_pectoral_muscle(img_otsu, row['view'])\n",
    "        img_clahe = self.apply_clahe(img_muscle)\n",
    "        img_patch, mask_patch = self.extract_lesion_patch(img_clahe, mask)\n",
    "        img_aug, mask_aug = self.apply_augmentation(img_patch, mask_patch)\n",
    "        \n",
    "        # Plotting\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        axes[0,0].imshow(img_raw_norm, cmap='gray'); axes[0,0].set_title(f'1. Raw ({row[\"view\"]})')\n",
    "        axes[0,1].imshow(img_otsu, cmap='gray'); axes[0,1].set_title('2. Otsu')\n",
    "        axes[0,2].imshow(img_muscle, cmap='gray'); axes[0,2].set_title('3. Muscle Removed')\n",
    "        axes[1,0].imshow(img_clahe, cmap='gray'); axes[1,0].set_title('4. CLAHE')\n",
    "        \n",
    "        overlay_patch = np.stack([img_patch]*3, axis=-1)\n",
    "        overlay_patch[:, :, 0] = np.where(mask_patch > 0.5, 1.0, overlay_patch[:, :, 0])\n",
    "        axes[1,1].imshow(overlay_patch); axes[1,1].set_title('5. Patch')\n",
    "        \n",
    "        overlay_aug = np.stack([img_aug]*3, axis=-1)\n",
    "        overlay_aug[:, :, 0] = np.where(mask_aug > 0.5, 1.0, overlay_aug[:, :, 0])\n",
    "        axes[1,2].imshow(overlay_aug); axes[1,2].set_title('6. Augmented')\n",
    "\n",
    "        plt.suptitle(f\"ID: {row['patient_id']} | Label: {row['label']} | View: {row['view']}\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # SAVE instead of Show\n",
    "        filename = f\"sample_{file_counter:02d}_{row['patient_id']}_{row['view']}.png\"\n",
    "        plt.savefig(os.path.join(save_folder, filename))\n",
    "        plt.close(fig) # Close memory to avoid overflow\n",
    "\n",
    "def run_pipeline():\n",
    "    processor = CBISDDSM_Preprocessor()\n",
    "    df = processor.load_and_filter_manifest()\n",
    "    \n",
    "    if df is not None:\n",
    "        train, val, test = processor.create_group_split()\n",
    "        print(f\"Split concluded: Train={len(train)}, Val={len(val)}, Test={len(test)}\")\n",
    "        \n",
    "        processor.compute_class_weights(train)\n",
    "        \n",
    "        print(\"\\n>> Validating pipeline steps on sample...\")\n",
    "\n",
    "        # EXECUTE BATCH SAVING\n",
    "        # Saves 20 images (10 MLO, 10 CC) to /kaggle/working/pipeline_verification/\n",
    "        processor.save_verification_batch(n_samples=20)\n",
    "\n",
    "        # EXECUTE MLO TEST\n",
    "        # Try to find an MLO sample to demonstrate muscle removal\n",
    "        \"\"\"\n",
    "        mlo_samples = df[df['view'] == 'MLO'].index\n",
    "        idx = mlo_samples[0] if len(mlo_samples) > 0 else 0\n",
    "        processor.visualize_sample(idx=idx)\n",
    "        \"\"\"\n",
    "\n",
    "    print(\"\\n>> Process finished...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}